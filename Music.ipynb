{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Requirements\n",
    "from music21 import *\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputting the Data/Reading the Dataset\n",
    "\n",
    "def midiread(file):\n",
    "    notes = []\n",
    "    parsenotes = None\n",
    "    midi = converter.parse(file) #parsing \n",
    "    GroupbyInstruments = instrument.partitionByInstrument(midi) #different instruments grouping\n",
    "    Chord = []\n",
    "    \n",
    "    \n",
    "    for part in GroupbyInstruments.parts:\n",
    "        parsenotes = part.recurse() \n",
    "        for i in parsenotes: \n",
    "            if type(i) == note.Note: #if type is a note\n",
    "                notes.append(str(i.pitch)) #appending to notes\n",
    "        \n",
    "            elif type(i) == chord.Chord: #if type is a chord\n",
    "                for j in i.normalOrder:\n",
    "                    Chord.append(str(j)) #appending to chords    \n",
    "                notes.append('.'.join(Chord))\n",
    "\n",
    "    notes = np.array(notes) \n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appass_1.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2001 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
      "  TranslateWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appass_2.mid\n",
      "appass_3.mid\n",
      "bach_846.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=8, channel=None, data=b'Copyright 2004 by Bernd Kr\\xfcger.'>; getting generic Instrument\n",
      "  TranslateWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bach_847.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=7, channel=None, data=b'Copyright 2004 by Bernd Kr\\xfcger.'>; getting generic Instrument\n",
      "  TranslateWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bach_850.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=0, channel=None, data=b'Pr\\xe4ludium und Fuge in D-Dur, BWV 850'>; getting generic Instrument\n",
      "  TranslateWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=8, channel=None, data=b'Copyright 1997 by Bernd Kr\\xfcger.'>; getting generic Instrument\n",
      "  TranslateWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beethoven_hammerklavier_1.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2008 by Bernd Krueger'>; getting generic Instrument\n",
      "  TranslateWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beethoven_hammerklavier_2.mid\n",
      "beethoven_hammerklavier_3.mid\n",
      "beethoven_hammerklavier_4.mid\n",
      "beethoven_les_adieux_1.mid\n",
      "beethoven_les_adieux_2.mid\n",
      "beethoven_les_adieux_3.mid\n",
      "beethoven_opus10_1.mid\n",
      "beethoven_opus10_2.mid\n",
      "beethoven_opus10_3.mid\n",
      "beethoven_opus22_1.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2009 by Bernd Krueger'>; getting generic Instrument\n",
      "  TranslateWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beethoven_opus22_2.mid\n",
      "beethoven_opus22_3.mid\n",
      "beethoven_opus22_4.mid\n",
      "beethoven_opus90_1.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2010 by Bernd Krueger'>; getting generic Instrument\n",
      "  TranslateWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beethoven_opus90_2.mid\n",
      "islamei.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2000 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
      "  TranslateWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mond_1.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=0, channel=None, data=b'Mondscheinsonate; der Gr\\xe4fin Giulietta Guiccardi gewidmet'>; getting generic Instrument\n",
      "  TranslateWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=6, channel=None, data=b'Copyright \\xa9 1998 by Bernd Krueger'>; getting generic Instrument\n",
      "  TranslateWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mond_2.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 1998 by Bernd Krueger'>; getting generic Instrument\n",
      "  TranslateWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mond_3.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 1998 by Bernd Krueger'>; getting generic Instrument\n",
      "  TranslateWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathetique_1.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Beethoven Sonata No. 8 C minor, Grand Sonate path\\xe9tique 1. Movement'>; getting generic Instrument\n",
      "  TranslateWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2003 by Bernd Krueger'>; getting generic Instrument\n",
      "  TranslateWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathetique_2.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=6, channel=None, data=b'Beethoven Sonata No. 8 C minor, Grand Sonate path\\xe9tique 2. Movement'>; getting generic Instrument\n",
      "  TranslateWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=7, channel=None, data=b'Copyright \\xa9 2003 by Bernd Krueger'>; getting generic Instrument\n",
      "  TranslateWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathetique_3.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Beethoven Sonata No. 8 C minor, Grand Sonate path\\xe9tique 3. Movement'>; getting generic Instrument\n",
      "  TranslateWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waldstein_1.mid\n",
      "waldstein_2.mid\n",
      "waldstein_3.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\music21\\midi\\translate.py:885: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=6, channel=None, data=b'Copyright \\xa9 2003 by Bernd Krueger'>; getting generic Instrument\n",
      "  TranslateWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "#Inputting the Data/Reading the Dataset\n",
    "\n",
    "midifiles = []\n",
    "reading = []\n",
    "path = \"C:/Users/14033/Documents/ENSE 480/ENSE 480 Project/archive/\" #dataset path\n",
    "ospath = os.listdir(path)\n",
    "\n",
    "#reading files\n",
    "for i in ospath:\n",
    "    if i.endswith(\".mid\"):\n",
    "        midifiles.append(i)\n",
    "        \n",
    "\n",
    "#reading each file        \n",
    "for i in midifiles:\n",
    "    print(i)\n",
    "    reading.append(midiread(path+i)) #appending to reading list\n",
    "    \n",
    "reading = np.array(reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89043\n"
     ]
    }
   ],
   "source": [
    "#Dataset Analyses/Extracting Notes that are commonly occurring\n",
    "\n",
    "Notes = []\n",
    "\n",
    "for n in reading:\n",
    "    for i in n:\n",
    "        Notes.append(i)\n",
    "print(len(Notes))\n",
    "\n",
    "#calculating and storing freqency of each note\n",
    "frequency_each_note = dict(Counter(Notes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "#Dataset Analyses/Extracting Notes that are commonly occurring\n",
    "\n",
    "notesfrequency = []\n",
    "for Notes, Notes_Count in frequency_each_note.items():\n",
    "    if Notes_Count >= 80: #if the note frequency is equal to or above the cound of 80 appending it to the \"notesfrequency\" list\n",
    "        notesfrequency.append(Notes)\n",
    "        \n",
    "\n",
    "print(len(notesfrequency)) #printing the number of notes that have freqeuncy of 80 or above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the Output and Input Sequence for our LSTM Model\n",
    "\n",
    "#appending to a new music list which will inputted into LSTM model\n",
    "music= []\n",
    "temporary = []\n",
    "for i in reading:\n",
    "    for j in i:\n",
    "        if j in notesfrequency:\n",
    "            temporary.append(j)            \n",
    "    music.append(temporary)\n",
    "    \n",
    "music = np.array(music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the Output and Input Sequence for our LSTM Model\n",
    "\n",
    "timesteps = 32\n",
    "x = list()\n",
    "y = list()\n",
    "\n",
    "for notes in music:\n",
    "    for i in range(0, len(notes) - timesteps, 1):        \n",
    "        x.append(notes[i:i + timesteps])\n",
    "        y.append(notes[i + timesteps])\n",
    "\n",
    "y=np.array(y)        \n",
    "x=np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the Output and Input Sequence for our LSTM Model\n",
    "\n",
    "xunique = x.ravel()\n",
    "xunique = set(xunique)\n",
    "xunique = list(xunique)\n",
    "\n",
    "# x note to int [number value]\n",
    "xnoteint = [(notex, valuex) for valuex, notex in enumerate(xunique)]\n",
    "xnoteint = dict(xnoteint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the Output and Input Sequence for our LSTM Model\n",
    "\n",
    "#assigning special integer to every x note\n",
    "sequencex = list()\n",
    "for i in x:\n",
    "    temporary = list()\n",
    "    for j in i:\n",
    "        temporary.append(xnoteint[j])\n",
    "    sequencex.append(temporary)\n",
    "    \n",
    "sequencex = np.array(sequencex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the Output and Input Sequence for our LSTM Model\n",
    "yunique = set(y)\n",
    "yunique = list(yunique)\n",
    "\n",
    "# y note to int [number value]\n",
    "ynoteint = [(notey, valuey) for valuey, notey in enumerate(yunique)] \n",
    "ynoteint = dict(ynoteint)\n",
    "\n",
    "#assigning special integer to every y note\n",
    "sequencey = list()\n",
    "for i in y:\n",
    "    sequencey.append(ynoteint[i])\n",
    "\n",
    "sequencey=np.array(sequencey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the Output and Input Sequence for our LSTM Model\n",
    "\n",
    "#test_size = 0.4/40% [Assesment Data] and Test Data = 60%\n",
    "trX, valX, trY, valY = train_test_split(sequencex,sequencey,test_size=0.4,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building LSTM Model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128,return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9324/9325 [============================>.] - ETA: 0s - loss: 3.1434\n",
      "Epoch 1: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 751s 80ms/step - loss: 3.1434 - val_loss: 2.9195\n",
      "Epoch 2/20\n",
      "9325/9325 [==============================] - ETA: 0s - loss: 2.8541\n",
      "Epoch 2: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 749s 80ms/step - loss: 2.8541 - val_loss: 2.7660\n",
      "Epoch 3/20\n",
      "9324/9325 [============================>.] - ETA: 0s - loss: 2.7562\n",
      "Epoch 3: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 748s 80ms/step - loss: 2.7562 - val_loss: 2.6392\n",
      "Epoch 4/20\n",
      "9325/9325 [==============================] - ETA: 0s - loss: 2.6956\n",
      "Epoch 4: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 772s 83ms/step - loss: 2.6956 - val_loss: 2.5616\n",
      "Epoch 5/20\n",
      "9325/9325 [==============================] - ETA: 0s - loss: 2.6533\n",
      "Epoch 5: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 878s 94ms/step - loss: 2.6533 - val_loss: 2.5130\n",
      "Epoch 6/20\n",
      "9325/9325 [==============================] - ETA: 0s - loss: 2.6196\n",
      "Epoch 6: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 924s 99ms/step - loss: 2.6196 - val_loss: 2.4843\n",
      "Epoch 7/20\n",
      "9325/9325 [==============================] - ETA: 0s - loss: 2.5931\n",
      "Epoch 7: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 913s 98ms/step - loss: 2.5931 - val_loss: 2.4487\n",
      "Epoch 8/20\n",
      "9325/9325 [==============================] - ETA: 0s - loss: 2.5712\n",
      "Epoch 8: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 1171s 126ms/step - loss: 2.5712 - val_loss: 2.4204\n",
      "Epoch 9/20\n",
      "9325/9325 [==============================] - ETA: 0s - loss: 2.5549\n",
      "Epoch 9: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 1024s 110ms/step - loss: 2.5549 - val_loss: 2.4012\n",
      "Epoch 10/20\n",
      "9325/9325 [==============================] - ETA: 0s - loss: 2.5405\n",
      "Epoch 10: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 801s 86ms/step - loss: 2.5405 - val_loss: 2.3867\n",
      "Epoch 11/20\n",
      "9324/9325 [============================>.] - ETA: 0s - loss: 2.5262\n",
      "Epoch 11: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 717s 77ms/step - loss: 2.5262 - val_loss: 2.3722\n",
      "Epoch 12/20\n",
      "9324/9325 [============================>.] - ETA: 0s - loss: 2.5138\n",
      "Epoch 12: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 682s 73ms/step - loss: 2.5138 - val_loss: 2.3632\n",
      "Epoch 13/20\n",
      "9325/9325 [==============================] - ETA: 0s - loss: 2.5050\n",
      "Epoch 13: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 721s 77ms/step - loss: 2.5050 - val_loss: 2.3329\n",
      "Epoch 14/20\n",
      "9325/9325 [==============================] - ETA: 0s - loss: 2.4941\n",
      "Epoch 14: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 797s 85ms/step - loss: 2.4941 - val_loss: 2.3230\n",
      "Epoch 15/20\n",
      "9324/9325 [============================>.] - ETA: 0s - loss: 2.4846\n",
      "Epoch 15: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 725s 78ms/step - loss: 2.4846 - val_loss: 2.3149\n",
      "Epoch 16/20\n",
      "9325/9325 [==============================] - ETA: 0s - loss: 2.4790\n",
      "Epoch 16: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 740s 79ms/step - loss: 2.4790 - val_loss: 2.3156\n",
      "Epoch 17/20\n",
      "9325/9325 [==============================] - ETA: 0s - loss: 2.4729\n",
      "Epoch 17: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 743s 80ms/step - loss: 2.4729 - val_loss: 2.3004\n",
      "Epoch 18/20\n",
      "9325/9325 [==============================] - ETA: 0s - loss: 2.4672\n",
      "Epoch 18: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 754s 81ms/step - loss: 2.4672 - val_loss: 2.2847\n",
      "Epoch 19/20\n",
      "9325/9325 [==============================] - ETA: 0s - loss: 2.4605\n",
      "Epoch 19: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 755s 81ms/step - loss: 2.4605 - val_loss: 2.2956\n",
      "Epoch 20/20\n",
      "9325/9325 [==============================] - ETA: 0s - loss: 2.4545\n",
      "Epoch 20: saving model to best_model.h5\n",
      "9325/9325 [==============================] - 757s 81ms/step - loss: 2.4545 - val_loss: 2.2746\n"
     ]
    }
   ],
   "source": [
    "#Training Data\n",
    "\n",
    "#when the training is occuring, a checkpoint to save model that is best\n",
    "mc = ModelCheckpoint('best_model.h5', monitor = 'val_loss', mode = 'min', onlysavebest = True, verbose = 1)\n",
    "\n",
    "#model is being trained with epochs=20 and batch_size=128\n",
    "history = model.fit(np.array(trX),np.array(trY),batch_size=128,epochs=20, validation_data=(np.array(valX),np.array(valY)),verbose = 1, callbacks = [mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 428ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "[59, 16, 8, 43, 60, 6, 48, 62, 2, 4, 7, 37, 51, 35, 53, 15, 42, 33, 16, 45, 59, 60, 48, 4, 14, 57, 2, 2, 1, 48, 18, 48, 18, 31, 6, 35, 2, 61, 4, 50]\n"
     ]
    }
   ],
   "source": [
    "#Generate Music with LSTM Model\n",
    "\n",
    "preds=[]\n",
    "for i in range(40):\n",
    "\n",
    "    musicrandom = valX[np.random.randint(0,len(valX)-1)].reshape(1,timesteps)\n",
    "\n",
    "    probability = model.predict(musicrandom)[0]\n",
    "    predictiony = np.argmax(probability, axis = 0)\n",
    "    preds.append(predictiony)\n",
    "\n",
    "    musicrandomindex_0 = musicrandom[0]\n",
    "    lenmusicrandom = len(musicrandom[0])\n",
    "    \n",
    "    musicrandom = np.insert(musicrandomindex_0, lenmusicrandom, predictiony)\n",
    "    musicrandom = musicrandom[1:]\n",
    "    \n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Data [Integer to Notes]\n",
    "xintnote = [(valuex, notex) for valuex, notex in enumerate(xunique)]\n",
    "xintnote = dict(xintnote)\n",
    "\n",
    "notespredicted = list()\n",
    "for i in preds:\n",
    "    notespredicted.append(xintnote[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'musictest.mid'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate MIDI File from the Notes\n",
    "offset = 0\n",
    "noutput = list()\n",
    "\n",
    "for i in notespredicted:\n",
    "    if i.isdigit(): #chord\n",
    "        nchord = i.split('.')\n",
    "        n = list()\n",
    "        for cnote in nchord:\n",
    "            cnote = int(cnote)\n",
    "            nn = note.Note(cnote)\n",
    "            nn.storedInstrument = instrument.Piano()\n",
    "            n.append(note.Note(nn))    \n",
    "        \n",
    "        nc = chord.Chord(n)\n",
    "        nc.offset = offset\n",
    "        noutput.append(nc)\n",
    "            \n",
    "    elif ('.' in i): #chord\n",
    "        nchord = i.split('.')\n",
    "        n = list()\n",
    "        for cnote in nchord:\n",
    "            cnote = int(cnote)\n",
    "            nn = note.Note(cnote)\n",
    "            nn.storedInstrument = instrument.Piano()\n",
    "            n.append(note.Note(nn))    \n",
    "        \n",
    "        nc = chord.Chord(n)\n",
    "        nc.offset = offset\n",
    "        noutput.append(nc)\n",
    "            \n",
    "    else: #note\n",
    "        nn = note.Note(i) \n",
    "        nn.offset = offset\n",
    "        nn.storedInstrument = instrument.Piano()\n",
    "        noutput.append(nn)\n",
    "        \n",
    "    offset = offset + 0.5\n",
    "\n",
    "midi_stream = stream.Stream(noutput)\n",
    "midi_stream.write('midi', fp='musictest.mid') #outputting the music creation to musictest.mid which is a MIDI file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
